{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6610ecac-361c-482e-9d02-b6e69ef01620",
   "metadata": {},
   "source": [
    "# Money Diaries Webscraping & Data Transformation \n",
    "\n",
    "Refinery29's \"Money Diary\" series features first-hand accounts from individuals detailing their personal financial information and spending habits. In this project, I have developed a web scraper to extract the raw, unformatted data from these published diaries. I then transform and clean the data before completing a thorough quantitative analysis, enabling deeper insights into the financial lives of the featured diarists.\\\n",
    "https://www.refinery29.com/en-us/money-diary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a67bba-a0fb-41af-98db-f2531a738c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import us\n",
    "import time\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a88a5-7f86-4f30-8cc1-8426adb1de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing helper functions from Money_Diaries_helper.pynb\n",
    "from Money_Diaries_helper import get_article_info\n",
    "from Money_Diaries_helper import get_article_text\n",
    "from Money_Diaries_helper import extract_salary\n",
    "from Money_Diaries_helper import extract_state\n",
    "from Money_Diaries_helper import get_monthly_expenses\n",
    "from Money_Diaries_helper import get_age\n",
    "from Money_Diaries_helper import get_occupation\n",
    "from Money_Diaries_helper import get_industry\n",
    "from Money_Diaries_helper import get_weekly_spend\n",
    "from Money_Diaries_helper import get_mortgage_rent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7592b9-45f8-426d-9bdd-87587cf900f2",
   "metadata": {},
   "source": [
    "### Scraping Titles and URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90ae5db0-7903-4971-9cf2-2c7856698201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred on page 59: All arrays must be of the same length\n",
      "Warning: No data returned for page 59\n",
      "Successfully combined all pages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.refinery29.com/en-us/editor-washington-80k-money-diary</td>\n",
       "      <td>A Week In Washington, D.C. On An $80,000 Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.refinery29.com/en-us/forensic-accountant-virginia-108k-money-diary</td>\n",
       "      <td>A Week In Virginia On A $108,280 Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.refinery29.com/en-us/historic-preservation-specialist-hawaii-36k-money-diary</td>\n",
       "      <td>A Week On O‘ahu, HI On A $36,000 Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.refinery29.com/en-us/project-manager-salt-lake-city-224k-joint-salary-money-diary</td>\n",
       "      <td>A Week In Salt Lake City On A $224,000 Joint Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.refinery29.com/en-us/strategist-boston-81k-money-diary</td>\n",
       "      <td>A Week In Boston On An $81,000 Salary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             url  \\\n",
       "0                             https://www.refinery29.com/en-us/editor-washington-80k-money-diary   \n",
       "1                 https://www.refinery29.com/en-us/forensic-accountant-virginia-108k-money-diary   \n",
       "2       https://www.refinery29.com/en-us/historic-preservation-specialist-hawaii-36k-money-diary   \n",
       "3  https://www.refinery29.com/en-us/project-manager-salt-lake-city-224k-joint-salary-money-diary   \n",
       "4                             https://www.refinery29.com/en-us/strategist-boston-81k-money-diary   \n",
       "\n",
       "                                                 title  \n",
       "0      A Week In Washington, D.C. On An $80,000 Salary  \n",
       "1              A Week In Virginia On A $108,280 Salary  \n",
       "2              A Week On O‘ahu, HI On A $36,000 Salary  \n",
       "3  A Week In Salt Lake City On A $224,000 Joint Salary  \n",
       "4                A Week In Boston On An $81,000 Salary  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get article titles and URLs\n",
    "article_title_url = []\n",
    "\n",
    "for i in range(1, nb_of_pages + 1):\n",
    "    result = get_article_info(i)\n",
    "    if result is not None:\n",
    "        article_title_url.append(result)\n",
    "    else:\n",
    "        print(f\"Warning: No data returned for page {i}\")\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "if article_title_url:\n",
    "    article_title_url = pd.concat(article_title_url, ignore_index=True)\n",
    "    print(\"Successfully combined all pages.\")\n",
    "else:\n",
    "    print(\"No data was retrieved from any page.\")\n",
    "\n",
    "article_title_url.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef55ff9-ab56-476f-b80c-6c49f1ad46d7",
   "metadata": {},
   "source": [
    "### Processing Money Data\n",
    "Sarlary, location, joint, hourly, monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65b3904e-5696-4e4b-80b9-eec583927d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process money data\n",
    "money_data = article_title_url.copy()\n",
    "money_data['lowercase_title'] = money_data['title'].str.lower()\n",
    "\n",
    "money_data['salary'] = money_data['title'].apply(extract_salary)\n",
    "money_data['location'] = money_data['title'].str.replace(\"A Week In \", \"\").str.replace(\"On .*\", \"\", regex=True) ## o'ahu \"a week on\" \n",
    "money_data['joint'] = money_data['lowercase_title'].str.contains(\"joint\")\n",
    "money_data['hourly'] = money_data['lowercase_title'].str.contains(\"hour\")\n",
    "money_data['monthly'] = money_data['lowercase_title'].str.contains(\"month\")\n",
    "\n",
    "# Replace one broken URL\n",
    "money_data['url'] = money_data['url'].replace(\n",
    "    \"https://www.refinery29.com/en-us/money-diary-wyoming-education-program-specialist-salary\",\n",
    "    \"https://www.refinery29.com/en-gb/money-diary-wyoming-education-program-specialist-salary\"\n",
    ")\n",
    "\n",
    "# fix for when location is the state \n",
    "money_data['state'] = money_data['location'].apply(extract_state)\n",
    "money_data['city'] = money_data['location'].str.extract(r'^([^,]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf27a9-f87b-4e20-8ccb-833f28c3ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by \"week\"\n",
    "money_data = money_data[money_data['lowercase_title'].str.contains(\"week\")]\n",
    "\n",
    "money_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1273dbbb-f9da-4de5-bd45-aa2fb421130c",
   "metadata": {},
   "source": [
    "### Scraping article info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5715d2-5452-4154-9f78-6dadff9d07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_article_text(url):\n",
    "    return get_article_text(url)\n",
    "\n",
    "# Split into two batches for processing\n",
    "batch_size = 750\n",
    "money_data_first = money_data.iloc[:batch_size].copy()\n",
    "money_data_second = money_data.iloc[batch_size:].copy()\n",
    "\n",
    "# Function to process batch\n",
    "def process_batch(money_data_batch):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        article_texts = list(executor.map(fetch_article_text, money_data_batch['url']))\n",
    "        print(article_texts)\n",
    "    money_data_batch['article_text'] = article_texts\n",
    "    return money_data_batch\n",
    "\n",
    "\n",
    "# Process the first and second batches in parallel\n",
    "all_article_text_first = process_batch(money_data_first)\n",
    "all_article_text_second = process_batch(money_data_second)\n",
    "\n",
    "# Combine batches\n",
    "all_article_text = pd.concat([all_article_text_first, all_article_text_second], ignore_index=True)\n",
    "\n",
    "csv_file_name = \"scraped_article_text.csv\"\n",
    "all_article_text.to_csv(csv_file_name, index=False)\n",
    "\n",
    "print(f\"Data has been successfully saved to {csv_file_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131731ca-4cfa-4be1-84d1-c028ebad8e40",
   "metadata": {},
   "source": [
    "### Using the CSV scraped once for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "374180b3-3c64-4145-9a25-5b6c7f8ebe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_article_text = pd.read_csv(\"scraped_article_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f8efb-9ea8-4e19-a5d9-5d5d573cccdb",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09414ad3-05cd-4234-a66f-bf03c61e1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1727 entries, 0 to 1726\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   url              1727 non-null   object \n",
      " 1   title            1727 non-null   object \n",
      " 2   lowercase_title  1727 non-null   object \n",
      " 3   salary           1684 non-null   float64\n",
      " 4   location         1727 non-null   object \n",
      " 5   joint            1727 non-null   bool   \n",
      " 6   hourly           1727 non-null   bool   \n",
      " 7   monthly          1727 non-null   bool   \n",
      " 8   state            1528 non-null   object \n",
      " 9   city             1727 non-null   object \n",
      " 10  article_text     1727 non-null   object \n",
      "dtypes: bool(3), float64(1), object(7)\n",
      "memory usage: 113.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_article_text.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bb495ab-5158-43fb-b5ad-a071766c5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1727 entries, 0 to 1726\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   url              1727 non-null   object \n",
      " 1   title            1727 non-null   object \n",
      " 2   lowercase_title  1727 non-null   object \n",
      " 3   salary           1684 non-null   float64\n",
      " 4   location         1727 non-null   object \n",
      " 5   joint            1727 non-null   bool   \n",
      " 6   hourly           1727 non-null   bool   \n",
      " 7   monthly          1727 non-null   bool   \n",
      " 8   state            1528 non-null   object \n",
      " 9   city             1727 non-null   object \n",
      " 10  article_text     1727 non-null   object \n",
      "dtypes: bool(3), float64(1), object(7)\n",
      "memory usage: 113.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns with names that start with 'Unnamed:'\n",
    "all_article_text = all_article_text.loc[:, ~all_article_text.columns.str.contains('^Unnamed')]\n",
    "print(all_article_text.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7cc646-5688-451f-89ae-4b9c8ce94542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Flatten the list if it's a list of lists\n",
    "    if isinstance(text, list):\n",
    "        flattened_text = []\n",
    "        for item in text:\n",
    "            if isinstance(item, list):\n",
    "                flattened_text.extend(item)\n",
    "            else:\n",
    "                flattened_text.append(item)\n",
    "\n",
    "        # Convert everything to a string and remove HTML tags\n",
    "        cleaned_text = ' '.join([BeautifulSoup(str(t), \"html.parser\").get_text() for t in flattened_text])\n",
    "    else:\n",
    "        # If it's not a list, just clean the text directly\n",
    "        cleaned_text = BeautifulSoup(str(text), \"html.parser\").get_text()\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43f17196-e756-4a85-8fa1-10380e5a6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_text['article_text'] = all_article_text['article_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85879573-eafa-4bab-b96b-d288be5259e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1727 entries, 0 to 1726\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   url              1727 non-null   object \n",
      " 1   title            1727 non-null   object \n",
      " 2   lowercase_title  1727 non-null   object \n",
      " 3   salary           1684 non-null   float64\n",
      " 4   location         1727 non-null   object \n",
      " 5   joint            1727 non-null   bool   \n",
      " 6   hourly           1727 non-null   bool   \n",
      " 7   monthly          1727 non-null   bool   \n",
      " 8   state            1528 non-null   object \n",
      " 9   city             1727 non-null   object \n",
      " 10  article_text     1727 non-null   object \n",
      "dtypes: bool(3), float64(1), object(7)\n",
      "memory usage: 113.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(all_article_text.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f66e3-3cd0-413c-9e98-beb78e506c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'lowercase_title' is a string and handle NaN values\n",
    "#all_monthly_expenses['lowercase_title'] = all_monthly_expenses['lowercase_title'].fillna('').astype(str)\n",
    "\n",
    "# Process expenses and filter data\n",
    "all_monthly_expenses = all_article_text.copy()\n",
    "all_monthly_expenses['monthly_expenses'] = all_monthly_expenses['article_text'].apply(get_monthly_expenses)\n",
    "\n",
    "# Filter out rows where 'lowercase_title' contains specific terms\n",
    "all_monthly_expenses = all_monthly_expenses[\n",
    "    ~all_monthly_expenses['lowercase_title'].str.contains(\"couple's|couples|5 money diaries\", regex=True)\n",
    "]\n",
    "\n",
    "print(all_monthly_expenses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2a6be9c8-a3c7-41ad-b9d7-84514b66d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        a week in washington, d.c. on an $80,000 salary\n",
      "1                a week in virginia on a $108,280 salary\n",
      "2                a week on o‘ahu, hi on a $36,000 salary\n",
      "3    a week in salt lake city on a $224,000 joint salary\n",
      "4                  a week in boston on an $81,000 salary\n",
      "Name: lowercase_title, dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'lowercase_title' is a string and handle NaN values\n",
    "all_monthly_expenses['lowercase_title'] = all_monthly_expenses['lowercase_title'].astype(str).fillna('')\n",
    "\n",
    "# Verify the conversion\n",
    "print(all_monthly_expenses['lowercase_title'].head())\n",
    "print(all_monthly_expenses['lowercase_title'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d776b-5f93-4ab3-aa9a-582f13897ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Apply the filter\n",
    "    filtered_expenses = all_monthly_expenses[\n",
    "        ~all_monthly_expenses['lowercase_title'].str.contains(\"couple's|couples|5 money diaries\", regex=True)\n",
    "    ]\n",
    "    print(filtered_expenses)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b813780-d031-47d1-97da-dae3dff907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_monthly_expenses = all_monthly_expenses[\n",
    "    ~all_monthly_expenses['url'].str.contains(\"comparison\")\n",
    "]\n",
    "# Apply the get_age function to the 'article_text' column\n",
    "all_monthly_expenses['age'] = all_monthly_expenses['article_text'].apply(get_age)\n",
    "\n",
    "print(all_monthly_expenses[['article_text', 'age']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a9a686-cba1-41f2-b690-b0232a4971d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_monthly_expenses['occupation'] = all_monthly_expenses['article_text'].apply(get_occupation)\n",
    "print(all_monthly_expenses[['article_text', 'occupation']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78d694af-e686-458c-8457-221ab4c14f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              industry\n",
      "491        Travel/Tech\n",
      "1087             Legal\n",
      "316   Higher Education\n",
      "1544         Nonprofit\n",
      "342      Public Health\n"
     ]
    }
   ],
   "source": [
    "all_monthly_expenses['industry'] = all_monthly_expenses['article_text'].apply(get_industry)\n",
    "print(all_monthly_expenses[['industry']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd010d28-e4c1-4ff8-a596-eac5544a4967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     total_weekly_spend\n",
      "37              1103.77\n",
      "321              454.87\n",
      "331              232.47\n",
      "1142             343.78\n",
      "500              343.31\n"
     ]
    }
   ],
   "source": [
    "all_monthly_expenses['total_weekly_spend'] = all_monthly_expenses['article_text'].apply(get_weekly_spend)\n",
    "all_monthly_expenses['total_weekly_spend'].replace(0, pd.NA, inplace=True)\n",
    "print(all_monthly_expenses[['total_weekly_spend']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "910aba50-d3aa-4ac2-98e0-4fef6ad4c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1523 entries, 0 to 1726\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   url                 1523 non-null   object \n",
      " 1   title               1523 non-null   object \n",
      " 2   lowercase_title     1523 non-null   object \n",
      " 3   salary              1497 non-null   float64\n",
      " 4   location            1523 non-null   object \n",
      " 5   joint               1523 non-null   bool   \n",
      " 6   hourly              1523 non-null   bool   \n",
      " 7   monthly             1523 non-null   bool   \n",
      " 8   state               1523 non-null   object \n",
      " 9   city                1523 non-null   object \n",
      " 10  article_text        1523 non-null   object \n",
      " 11  monthly_expenses    1520 non-null   object \n",
      " 12  age                 1523 non-null   float64\n",
      " 13  occupation          1487 non-null   object \n",
      " 14  industry            1507 non-null   object \n",
      " 15  total_weekly_spend  1420 non-null   object \n",
      "dtypes: bool(3), float64(2), object(11)\n",
      "memory usage: 171.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "all_monthly_expenses = all_monthly_expenses.dropna(subset=['state'])\n",
    "all_monthly_expenses = all_monthly_expenses[all_monthly_expenses['state'].str.strip() != ''] \n",
    "\n",
    "all_monthly_expenses = all_monthly_expenses[all_monthly_expenses['url'].str.startswith('https://')]\n",
    "\n",
    "all_monthly_expenses = all_monthly_expenses.loc[:, ~all_monthly_expenses.columns.str.contains('^Unnamed')]\n",
    "print(all_monthly_expenses.info())\n",
    "\n",
    "#all_monthly_expenses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb619f08-f2e4-4e50-a2d4-75f4fe6cc6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to scraped_age_thru_industry.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = \"scraped_age_thru_industry.csv\"\n",
    "all_monthly_expenses.to_csv(csv_file_name, index=False)\n",
    "\n",
    "print(f\"Data has been successfully saved to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8ae81cde-e904-4103-a9ec-5b0bda757285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mortgage_rent(expenses):\n",
    "    expenses_df = pd.DataFrame(expenses, columns=['Type', 'Amount'])\n",
    "    rent_mortgage = expenses_df[expenses_df['Type'].str.contains(\"Rent|Mortgage\", case=False, na=False) & \n",
    "                                ~expenses_df['Type'].str.contains(\"insurance\", case=False, na=False)]\n",
    "    return rent_mortgage['Amount'].astype(float).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a32d0ca2-6bc7-4e98-9a38-aff180e97e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example of the get_mortgage_rent function\n",
    "def get_mortgage_rent(expenses):\n",
    "    expenses_df = pd.DataFrame(expenses, columns=['Type', 'Amount'])\n",
    "    rent_mortgage = expenses_df[expenses_df['Type'].str.contains(\"Rent|Mortgage\", case=False, na=False) & \n",
    "                                ~expenses_df['Type'].str.contains(\"insurance\", case=False, na=False)]\n",
    "    return rent_mortgage['Amount'].astype(float).tolist()\n",
    "\n",
    "# Split non-null and null expenses\n",
    "non_null_expenses = all_monthly_expenses.dropna(subset=['monthly_expenses'])\n",
    "null_expenses = all_monthly_expenses[all_monthly_expenses['monthly_expenses'].isna()]\n",
    "\n",
    "# Explode the 'monthly_expenses' list and split into 'Type' and 'Amount'\n",
    "share_for_housing = non_null_expenses.explode('monthly_expenses').copy()\n",
    "share_for_housing[['Type', 'Amount']] = share_for_housing['monthly_expenses'].str.split(':', expand=True)\n",
    "share_for_housing['Amount'] = share_for_housing['Amount'].str.replace(\",\", \"\").str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Ensure 'salary' column is numeric\n",
    "share_for_housing['salary'] = pd.to_numeric(share_for_housing['salary'], errors='coerce')\n",
    "\n",
    "# Apply get_mortgage_rent to each group of rows corresponding to the same 'id'\n",
    "if 'id' not in share_for_housing.columns:\n",
    "    share_for_housing['id'] = share_for_housing.index  # Create 'id' only if it doesn't exist\n",
    "\n",
    "# Group by 'id' and apply the get_mortgage_rent function to get the rent or mortgage amount\n",
    "share_for_housing['rent_mortgage'] = share_for_housing.groupby('id').apply(lambda x: get_mortgage_rent(list(zip(x['Type'], x['Amount'])))).reset_index(level=0, drop=True)\n",
    "\n",
    "# Check if 'rent_mortgage' contains lists and filter out rows where it does not\n",
    "share_for_housing = share_for_housing[share_for_housing['rent_mortgage'].apply(lambda x: isinstance(x, list) and len(x) == 1)]\n",
    "\n",
    "# Convert 'rent_mortgage' to float (since it will have exactly one element)\n",
    "share_for_housing['rent_mortgage'] = share_for_housing['rent_mortgage'].apply(lambda x: float(x[0]) if isinstance(x, list) else None)\n",
    "\n",
    "# Calculate the housing share\n",
    "share_for_housing['housing_share'] = share_for_housing.apply(\n",
    "    lambda row: row['rent_mortgage'] / row['salary'] if row['monthly'] else\n",
    "    row['rent_mortgage'] / (row['salary'] * 40 * 4) if row['hourly'] else\n",
    "    (row['rent_mortgage'] * 12) / row['salary'], axis=1\n",
    ")\n",
    "\n",
    "# Drop duplicates if any exist due to the previous operations\n",
    "share_for_housing = share_for_housing.drop_duplicates(subset=['id'])\n",
    "\n",
    "#print(share_for_housing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b8592c2-ac12-4be5-9825-3e92dd21a878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to final_money_diaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the final data\n",
    "csv_file_name = \"final_money_diaries.csv\"\n",
    "share_for_housing.to_csv(csv_file_name, index=False)\n",
    "\n",
    "print(f\"Data has been successfully saved to {csv_file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
