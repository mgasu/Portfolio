{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a0eb47-5000-4605-94a3-49f09d32cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984ce37-f576-4613-9ce8-8f60dee03854",
   "metadata": {},
   "source": [
    "### Libraries Used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903e853-bf5e-4498-9d35-805eb910e317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import os\n",
    "import us\n",
    "import time\n",
    "import requests\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cf9ca-dfed-4c9b-b221-3ebd3932e658",
   "metadata": {},
   "source": [
    "### Configuration and Custom Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf84a02-0c3b-4a92-8e79-caf28cd543d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "nb_of_pages = 62\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None to display all text in the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039fc38-d98d-4be8-b633-c84794173aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get article info\n",
    "def get_article_info(page_number):\n",
    "    try:\n",
    "        time.sleep(1)  # Respectful scraping with a pause\n",
    "        link = f\"https://www.refinery29.com/en-us/money-diary?page={page_number}\"\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "\n",
    "        html = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extracting titles and URLs based on HTML structure\n",
    "        titles = [span.text for span in html.select(\".title span\")]\n",
    "        regular_article_urls = [a['href'] for a in html.select(\".card a[href]\")]\n",
    "        article_url_hero = [a['href'] for a in html.select(\".hero-card-full-width a[href]\")]\n",
    "        article_urls = article_url_hero + regular_article_urls\n",
    "        urls = [\"https://www.refinery29.com\" + url for url in article_urls]\n",
    "        \n",
    "        # Filter out unwanted titles\n",
    "        filtered_titles = [title for title in titles if title not in [\"All Money Diaries\", \"The Secret Sauce To A Successful Budget\"]]\n",
    "        \n",
    "        if filtered_titles and urls:\n",
    "            return pd.DataFrame({'url': urls, 'title': filtered_titles})\n",
    "        else:\n",
    "            print(f\"No relevant data found on page {page_number}.\")\n",
    "            return None\n",
    "        \n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred on page {page_number}: {http_err}\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred on page {page_number}: {err}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201017db-7573-4144-8c47-6357a3ac6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get article text \n",
    "def get_article_text(url):\n",
    "    response = requests.get(url)\n",
    "    html = BeautifulSoup(response.content, 'html.parser')\n",
    "    return html.select(\".section-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f532862-a706-48f3-8e5f-4e18f4db37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to extract salary\n",
    "def extract_salary(title):\n",
    "    title_lower = title.lower()\n",
    "    \n",
    "    if \"hour\" in title_lower or \"month\" in title_lower:\n",
    "        salary = re.search(r\"\\$\\d+(?:\\.\\d+)?\", title_lower)\n",
    "        if salary:\n",
    "            return float(salary.group().replace('$', '').replace(',', '')) * 1000\n",
    "    \n",
    "    elif \"million\" in title_lower:\n",
    "        salary = re.search(r\"(\\d+\\.?\\d*) million\", title_lower)\n",
    "        if salary:\n",
    "            return float(salary.group(1).replace('.', '')) * 1000000\n",
    "    \n",
    "    else:\n",
    "        salary = re.search(r\"\\$\\d+k?\", title_lower)\n",
    "        if salary:\n",
    "            return float(salary.group().replace('k', '000').replace('$', '').replace(',', ''))\n",
    "    \n",
    "    #return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefe70f-7b5a-4ca5-b873-2c8e2a851511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to extract state\n",
    "def extract_state(location):\n",
    "    state_name = next((state for state in us.states.STATES if state.name in location), None)\n",
    "    \n",
    "    if state_name and \"New York\" not in location and \"Washington\" not in location and \"Kansas City\" not in location:\n",
    "        return state_name.abbr\n",
    "    elif \"New York City\" in location or \"NYC\" in location:\n",
    "        return \"NY\"\n",
    "    else:\n",
    "        match = re.search(r\"(?<=, )\\w+\", location)\n",
    "        return match.group(0) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94ada2-532a-4fb2-921f-b57dd69df927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get monthly expenses \n",
    "def get_monthly_expenses(article_text):\n",
    "    # Initialize the list to hold expenses\n",
    "    expenses = []\n",
    "    \n",
    "    # Parse the article text using BeautifulSoup\n",
    "    soup = BeautifulSoup(article_text, \"html.parser\")\n",
    "    \n",
    "    # Find the section that contains \"Monthly Expenses\"\n",
    "    monthly_expenses_section = soup.find_all(text=re.compile(r'Monthly Expenses'))\n",
    "\n",
    "    for section in monthly_expenses_section:\n",
    "        # Get the text following \"Monthly Expenses\"\n",
    "        parent = section.find_parent()\n",
    "        if parent:\n",
    "            # Extract all text following \"Monthly Expenses\"\n",
    "            text_content = parent.get_text(separator=' ', strip=True)\n",
    "            \n",
    "            # Clean and extract the expenses\n",
    "            cleaned = re.sub(r',', '', text_content)\n",
    "            extracted = re.findall(r\"[^\\.\\(\\):\\d]*?: \\$\\d+\", cleaned) #regex to scrape in the form Catergory: \n",
    "            expenses.extend(extracted)\n",
    "    \n",
    "    return expenses if expenses else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f3662-4b30-47d3-bf8c-0c9af21ba3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get age \n",
    "def get_age(article_text):\n",
    "    # Ensure article_text is a list of strings\n",
    "    if isinstance(article_text, str):\n",
    "        article_text = article_text.splitlines()\n",
    "    \n",
    "    # Find the line that contains 'Age:'\n",
    "    age_text = next((line for line in article_text if 'Age:' in line), None)\n",
    "    \n",
    "    if age_text:\n",
    "        # Debugging print statement\n",
    "        print(f\"Found line: {age_text}\")\n",
    "        \n",
    "        # Adjust the regex to be more flexible\n",
    "        match = re.search(r\"Age:\\s*(\\d+)\", age_text)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b89896-62ca-488b-941f-54ad1b8b8ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get occupation\n",
    "def get_occupation(article_text):\n",
    "    # Search for the 'Occupation:' label within the entire text\n",
    "    occupation = re.search(r\"Occupation:\\s*(.+?)(?=Industry|Age|Location|Salary|,|$)\", article_text, re.DOTALL)\n",
    "    \n",
    "    if occupation:\n",
    "        occupation_str = occupation.group(1)\n",
    "        \n",
    "        # Clean up any trailing unwanted text that might have been captured\n",
    "        occupation_str = re.sub(r\"\\b(Industry|Age|Location|Salary)\\b.*\", \"\", occupation_str)\n",
    "        \n",
    "        return occupation_str.strip()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61a2a7-b184-4c84-9e85-6a75d60fc012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get industry\n",
    "def get_industry(article_text):\n",
    "    # Search for the 'Industry:' label within the entire text\n",
    "    industry = re.search(r\"Industry:\\s*(.+?)(?=Age|Location|Salary|,|$)\", article_text, re.DOTALL)\n",
    "    \n",
    "    if industry:\n",
    "        industry_str = industry.group(1)\n",
    "        \n",
    "        # Clean up any trailing unwanted text that might have been captured\n",
    "        industry_str = re.sub(r\"\\b(Age|Location|Salary)\\b.*\", \"\", industry_str)\n",
    "        \n",
    "        return industry_str.strip()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820cd22-6efe-477d-aafc-c2ba1bca5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get weekly spend \n",
    "def get_weekly_spend(article_text):\n",
    "    # Find all occurrences of 'Daily Total: $' followed by the amount\n",
    "    amounts = re.findall(r\"Daily Total:\\s*\\$\\s*([\\d,]+\\.\\d{2}|\\d+)\", article_text)\n",
    "    \n",
    "    total_spend = 0.0\n",
    "    for amount in amounts:\n",
    "        # Sum the amounts after removing commas\n",
    "        total_spend += float(amount.replace(\",\", \"\"))\n",
    "    \n",
    "    return total_spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2718f-b7b2-4dde-bde7-ab9178930fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to get rent/morgtage \n",
    "def get_mortgage_rent(expenses):\n",
    "    expenses_df = pd.DataFrame(expenses, columns=['Type', 'Amount'])\n",
    "    rent_mortgage = expenses_df[expenses_df['Type'].str.contains(\"Rent|Mortgage\", case=False, na=False) & \n",
    "                                ~expenses_df['Type'].str.contains(\"insurance\", case=False, na=False)]\n",
    "    return rent_mortgage['Amount'].astype(float).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
